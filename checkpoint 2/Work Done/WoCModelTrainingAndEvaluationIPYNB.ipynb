{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###this is the second notebook pertaining to the WoC NLP project. the first part contains data preprocessing. this notebook aims to build a model on top of the processed dataset."
      ],
      "metadata": {
        "id": "GUqSSltWRzyx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef4tWPDTRx57",
        "outputId": "faa016a5-d0bc-475b-da5e-d710fbd84d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "             category  rating label  \\\n",
            "0  Home_and_Kitchen_5     5.0    CG   \n",
            "1  Home_and_Kitchen_5     5.0    CG   \n",
            "2  Home_and_Kitchen_5     5.0    CG   \n",
            "3  Home_and_Kitchen_5     1.0    CG   \n",
            "4  Home_and_Kitchen_5     5.0    CG   \n",
            "\n",
            "                                               text_  \\\n",
            "0  love this  well made sturdy and very comfortab...   \n",
            "1  love it a great upgrade from the original  ive...   \n",
            "2  this pillow saved my back i love the look and ...   \n",
            "3  missing information on how to use it but it is...   \n",
            "4  very nice set good quality we have had the set...   \n",
            "\n",
            "                                              tokens  \\\n",
            "0  ['love', 'this', ' ', 'well', 'made', 'sturdy'...   \n",
            "1  ['love', 'it', 'a', 'great', 'upgrade', 'from'...   \n",
            "2  ['this', 'pillow', 'saved', 'my', 'back', 'i',...   \n",
            "3  ['missing', 'information', 'on', 'how', 'to', ...   \n",
            "4  ['very', 'nice', 'set', 'good', 'quality', 'we...   \n",
            "\n",
            "                                      tokens_cleaned  \\\n",
            "0  ['love', 'well', 'made', 'sturdy', 'comfortabl...   \n",
            "1  ['love', 'great', 'upgrade', 'original', 'mine...   \n",
            "2  ['pillow', 'saved', 'back', 'love', 'look', 'f...   \n",
            "3  ['missing', 'information', 'use', 'great', 'pr...   \n",
            "4  ['nice', 'set', 'good', 'quality', 'set', 'two...   \n",
            "\n",
            "                                      tokens_stemmed  \\\n",
            "0  ['love', 'well', 'made', 'sturdi', 'comfort', ...   \n",
            "1  ['love', 'great', 'upgrad', 'origin', 'mine', ...   \n",
            "2  ['pillow', 'save', 'back', 'love', 'look', 'fe...   \n",
            "3  ['miss', 'inform', 'use', 'great', 'product', ...   \n",
            "4  ['nice', 'set', 'good', 'qualiti', 'set', 'two...   \n",
            "\n",
            "                                   tokens_lemmatized  \n",
            "0  ['love', 'well', 'make', 'sturdy', 'comfortabl...  \n",
            "1  ['love', 'great', 'upgrade', 'original', 'mine...  \n",
            "2  ['pillow', 'save', 'back', 'love', 'look', 'fe...  \n",
            "3  ['miss', 'information', 'use', 'great', 'produ...  \n",
            "4  ['nice', 'set', 'good', 'quality', 'set', 'two...  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40420 entries, 0 to 40419\n",
            "Data columns (total 8 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   category           40420 non-null  object \n",
            " 1   rating             40420 non-null  float64\n",
            " 2   label              40420 non-null  object \n",
            " 3   text_              40420 non-null  object \n",
            " 4   tokens             40420 non-null  object \n",
            " 5   tokens_cleaned     40420 non-null  object \n",
            " 6   tokens_stemmed     40420 non-null  object \n",
            " 7   tokens_lemmatized  40420 non-null  object \n",
            "dtypes: float64(1), object(7)\n",
            "memory usage: 2.5+ MB\n",
            "None\n",
            "\n",
            "Missing Values Summary:\n",
            "category             0\n",
            "rating               0\n",
            "label                0\n",
            "text_                0\n",
            "tokens               0\n",
            "tokens_cleaned       0\n",
            "tokens_stemmed       0\n",
            "tokens_lemmatized    0\n",
            "dtype: int64\n",
            "\n",
            "Training Set Size: 32336\n",
            "Testing Set Size: 8084\n",
            "\n",
            "Dataset preparation completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1.1: Load the preprocessed dataset\n",
        "# Replace 'preprocessed_dataset.csv' with your actual file name\n",
        "file_path = '/content/fakeReviewDataLemmatized.csv'\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1.2: Inspect the dataset structure\n",
        "print(\"Dataset Preview:\")\n",
        "print(dataset.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(dataset.info())\n",
        "\n",
        "# Step 1.3: Check for missing values\n",
        "print(\"\\nMissing Values Summary:\")\n",
        "print(dataset.isnull().sum())\n",
        "\n",
        "# Step 1.4: Split the dataset into training and testing sets\n",
        "# Using 'tokens_lemmatized' for text data and 'label' as the target\n",
        "X = dataset['tokens_lemmatized']  # Features (lemmatized tokens)\n",
        "y = dataset['label']  # Labels (classification target)\n",
        "\n",
        "# Convert the features to a suitable format (e.g., strings)\n",
        "X = X.apply(lambda x: ' '.join(eval(x)))  # Convert lists of tokens to strings\n",
        "\n",
        "# Splitting into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the splits\n",
        "print(\"\\nTraining Set Size:\", X_train.shape[0])\n",
        "print(\"Testing Set Size:\", X_test.shape[0])\n",
        "\n",
        "# Save the splits for later use\n",
        "X_train.to_csv('X_train.csv', index=False)\n",
        "y_train.to_csv('y_train.csv', index=False)\n",
        "X_test.to_csv('X_test.csv', index=False)\n",
        "y_test.to_csv('y_test.csv', index=False)\n",
        "\n",
        "print(\"\\nDataset preparation completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the training and testing datasets\n",
        "X_train = pd.read_csv('X_train.csv', header=None).squeeze(\"columns\")\n",
        "y_train = pd.read_csv('y_train.csv', header=None).squeeze(\"columns\")\n",
        "X_test = pd.read_csv('X_test.csv', header=None).squeeze(\"columns\")\n",
        "y_test = pd.read_csv('y_test.csv', header=None).squeeze(\"columns\")\n",
        "\n",
        "# Handle missing values\n",
        "X_train = X_train.fillna(\"\")\n",
        "X_test = X_test.fillna(\"\")\n",
        "\n",
        "# Create pipeline for Random Forest\n",
        "rf_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),  # Convert text to TF-IDF features\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Train the Random Forest model\n",
        "print(\"Training Random Forest...\")\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_rf = rf_pipeline.predict(X_test)\n",
        "print(\"\\nClassification Report for Random Forest:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(rf_pipeline, 'RandomForest_model.pkl')\n",
        "print(\"Random Forest model saved as RandomForest_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x45WHyD9YhCl",
        "outputId": "8cc75346-60a9-4132-bc51-c9cccbaa7738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n",
            "\n",
            "Classification Report for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.82      0.89      0.85      4055\n",
            "          OR       0.88      0.80      0.83      4029\n",
            "       label       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.84      8085\n",
            "   macro avg       0.90      0.89      0.89      8085\n",
            "weighted avg       0.84      0.84      0.84      8085\n",
            "\n",
            "Random Forest model saved as RandomForest_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline  # Import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "# Create pipeline for SVM\n",
        "svm_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),  # Convert text to TF-IDF features\n",
        "    ('classifier', SVC(probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "# Train the SVM model\n",
        "print(\"Training SVM...\")\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_svm = svm_pipeline.predict(X_test)\n",
        "print(\"\\nClassification Report for SVM:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(svm_pipeline, 'SVM_model.pkl')\n",
        "print(\"SVM model saved as SVM_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl9FPNTwhZ7-",
        "outputId": "e8fd5e82-19f1-45df-cfe5-12eb0a44db5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SVM...\n",
            "\n",
            "Classification Report for SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.89      0.87      0.88      4055\n",
            "          OR       0.88      0.90      0.89      4029\n",
            "       label       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.88      8085\n",
            "   macro avg       0.59      0.59      0.59      8085\n",
            "weighted avg       0.89      0.88      0.88      8085\n",
            "\n",
            "SVM model saved as SVM_model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create pipeline for Logistic Regression\n",
        "lr_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),  # Convert text to TF-IDF features\n",
        "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "print(\"Training Logistic Regression...\")\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_lr = lr_pipeline.predict(X_test)\n",
        "print(\"\\nClassification Report for Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(lr_pipeline, 'LogisticRegression_model.pkl')\n",
        "print(\"Logistic Regression model saved as LogisticRegression_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMRUrdR9ha5J",
        "outputId": "656af30e-52fb-46df-841f-6e4c0c16dd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "\n",
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.87      0.87      0.87      4055\n",
            "          OR       0.87      0.87      0.87      4029\n",
            "       label       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.87      8085\n",
            "   macro avg       0.58      0.58      0.58      8085\n",
            "weighted avg       0.87      0.87      0.87      8085\n",
            "\n",
            "Logistic Regression model saved as LogisticRegression_model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###here, we've tried three different models for our application and exported the respective pickle files. that completes steps 1 and 2 from checkpoint 2.\n",
        "\n",
        "\n",
        "Given the promising results from SVM model, we'll move ahead with fine tuning it and refining its performance."
      ],
      "metadata": {
        "id": "OdUb1aDIupDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Load the pretrained pipeline\n",
        "print(\"Loading the pretrained SVM model...\")\n",
        "svm_pipeline_pretrained = joblib.load(\"SVM_model.pkl\")  # Replace with your file path\n",
        "print(\"SVM model loaded successfully.\")\n",
        "\n",
        "# Extract the pre-fitted vectorizer and classifier\n",
        "tfidf_fitted = svm_pipeline_pretrained.named_steps['tfidf']\n",
        "svm_classifier = svm_pipeline_pretrained.named_steps['classifier']\n",
        "\n",
        "# Recreate the pipeline using the pre-fitted components\n",
        "svm_pipeline_final = Pipeline([\n",
        "    ('tfidf', tfidf_fitted),  # Use the pre-fitted TF-IDF vectorizer\n",
        "    ('classifier', svm_classifier)  # Use the pre-trained SVM classifier\n",
        "])\n",
        "\n",
        "# Save the final pipeline\n",
        "print(\"Saving the final pipeline...\")\n",
        "joblib.dump(svm_pipeline_final, \"SVM_pipeline_final.pkl\")\n",
        "print(\"Pipeline saved as SVM_pipeline_final.pkl\")\n",
        "\n",
        "# Test the pipeline\n",
        "print(\"Testing the pipeline...\")\n",
        "new_reviews = [\"This product is amazing!\", \"Terrible experience, never buying again.\"]\n",
        "predictions = svm_pipeline_final.predict(new_reviews)\n",
        "print(\"Predictions for new reviews:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn55Dt5Tu5_U",
        "outputId": "d9d5269d-4e37-4a73-8eef-a19ed4dd1e28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the pretrained SVM model...\n",
            "SVM model loaded successfully.\n",
            "Saving the final pipeline...\n",
            "Pipeline saved as SVM_pipeline_final.pkl\n",
            "Testing the pipeline...\n",
            "Predictions for new reviews: ['CG' 'OR']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###step 4 becomes redundant because we've already trained all the three models to check which one performs best. we've also done pipelining so that the model can take in raw text and perform preprocessing, vectorization, and classify the text all by itself."
      ],
      "metadata": {
        "id": "YbuhbRsLynlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###we now move towards evaluation of the models on the test dataset to find out which one performs best."
      ],
      "metadata": {
        "id": "06XuhdrBzs8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out irrelevant classes\n",
        "y_test_filtered = y_test[y_test.isin(['CG', 'OR'])]\n",
        "X_test_filtered = X_test[y_test.isin(['CG', 'OR'])]\n",
        "\n",
        "# Verify the unique classes\n",
        "print(\"Filtered unique classes:\", y_test_filtered.unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fVHJuBJ03Jw",
        "outputId": "1889a746-f904-4bda-8959-b7a638356369"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered unique classes: ['CG' 'OR']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the testing datasets\n",
        "X_test = pd.read_csv('/content/X_test.csv', header=None).squeeze(\"columns\").fillna(\"\")\n",
        "y_test = pd.read_csv('/content/y_test.csv', header=None).squeeze(\"columns\")\n",
        "\n",
        "# Filter out irrelevant classes (e.g., 'label')\n",
        "valid_classes = ['CG', 'OR']  # Define the classes to include\n",
        "filtered_indices = y_test.isin(valid_classes)  # Filter indices for valid classes\n",
        "X_test_filtered = X_test[filtered_indices]  # Filter X_test\n",
        "y_test_filtered = y_test[filtered_indices]  # Filter y_test\n",
        "\n",
        "# Verify the filtered dataset\n",
        "print(\"Filtered unique classes in y_test:\", y_test_filtered.unique())\n",
        "\n",
        "# Define paths to the saved models\n",
        "model_files = {\n",
        "    \"Random Forest\": \"/content/RandomForestModel.pkl\",\n",
        "    \"SVM\": \"/content/SVM_pipeline_final.pkl\",\n",
        "    \"Logistic Regression\": \"/content/LogisticRegressionModel.pkl\"\n",
        "}\n",
        "\n",
        "# Evaluate each model\n",
        "evaluation_results = {}\n",
        "\n",
        "for model_name, model_file in model_files.items():\n",
        "    print(f\"Evaluating Model: {model_name}\")\n",
        "\n",
        "    # Load the trained model\n",
        "    model = joblib.load(model_file)\n",
        "\n",
        "    # Make predictions on the filtered test dataset\n",
        "    y_pred = model.predict(X_test_filtered)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test_filtered, y_pred)\n",
        "    classification_rep = classification_report(y_test_filtered, y_pred, target_names=valid_classes)\n",
        "    confusion_mat = confusion_matrix(y_test_filtered, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    evaluation_results[model_name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Classification Report\": classification_rep,\n",
        "        \"Confusion Matrix\": confusion_mat\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_mat)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_rep)\n",
        "\n",
        "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Summary of results\n",
        "print(\"\\nModel Evaluation Summary:\")\n",
        "for model_name, metrics in evaluation_results.items():\n",
        "    print(f\"{model_name} - Accuracy: {metrics['Accuracy']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw_0MImGzHWp",
        "outputId": "0db9bb84-d16d-4a55-da44-112f934f8655"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered unique classes in y_test: ['CG' 'OR']\n",
            "Evaluating Model: Random Forest\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3596  459]\n",
            " [ 816 3213]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.82      0.89      0.85      4055\n",
            "          OR       0.88      0.80      0.83      4029\n",
            "\n",
            "    accuracy                           0.84      8084\n",
            "   macro avg       0.85      0.84      0.84      8084\n",
            "weighted avg       0.84      0.84      0.84      8084\n",
            "\n",
            "\n",
            "Accuracy: 0.8423\n",
            "--------------------------------------------------\n",
            "Evaluating Model: SVM\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3544  511]\n",
            " [ 418 3611]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.89      0.87      0.88      4055\n",
            "          OR       0.88      0.90      0.89      4029\n",
            "\n",
            "    accuracy                           0.89      8084\n",
            "   macro avg       0.89      0.89      0.89      8084\n",
            "weighted avg       0.89      0.89      0.89      8084\n",
            "\n",
            "\n",
            "Accuracy: 0.8851\n",
            "--------------------------------------------------\n",
            "Evaluating Model: Logistic Regression\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3527  528]\n",
            " [ 514 3515]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.87      0.87      0.87      4055\n",
            "          OR       0.87      0.87      0.87      4029\n",
            "\n",
            "    accuracy                           0.87      8084\n",
            "   macro avg       0.87      0.87      0.87      8084\n",
            "weighted avg       0.87      0.87      0.87      8084\n",
            "\n",
            "\n",
            "Accuracy: 0.8711\n",
            "--------------------------------------------------\n",
            "\n",
            "Model Evaluation Summary:\n",
            "Random Forest - Accuracy: 0.8423\n",
            "SVM - Accuracy: 0.8851\n",
            "Logistic Regression - Accuracy: 0.8711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###the above evaluation on the testing datasets confirms our initial suspicion that SVM is best (although marginally) among the three classifiers we are using."
      ],
      "metadata": {
        "id": "Oebyp8SZ2L8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Or6jihA42URo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}